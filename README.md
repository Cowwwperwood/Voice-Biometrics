
# Отчёт по проекту: Voice Biometrics

## 1. Введение

В рамках проекта реализована система голосовой биометрии, а именно: эмбедер для wav-файлов. Для обучения модели использовалось 70000 звуковых файлов (wav) для тренировочного набора и 3000 файлов для тестирования. Эти wav-ки представляли из себя голоса селебрити.

## 2. Постановка задачи

**Цель проекта:**  
Разработать модель, способную выдавать качественные эмбэдинги для звуковых файлов с голосом. Главная задача: построить такой эмбедер, в котором похожие голоса будут находится близко(по определенной метрике расстояния) в нашем многомерном пространстве, а непохожие - соотвественно далеко друг от друга. Основными задачами являются:

- Подготовка и предварительная обработка аудиоданных.
- Реализация архитектуры модели.
- Обучение модели и оценка её эффективности на тестовом наборе.
- Проведение экспериментов, анализ результатов и формулировка выводов.

## 3. Данные

**Тренировочный набор:** 70000 wav файлов c голосами селебрити

## 4. Предварительная обработка и аугментация данных

Для преобразования аудио сигналов использовалось лишь MFCC преобразование, в силу того, что мы обучали маленькую(относительно) модель, не подверженную переобучению. Если бы мы вдруг захотели усложнить модель(например, просто увеличить число параметров или в целом добавить новые архитектурные блоки), мы бы добавили определенные аугментации к данным, такие как маскирование по времени и частотам


## 5. Архитектура модели и методология

Для решения задачи классификации одной из главных задач было построить небольшую(относительно решения этой задачи) модель на 1 миллион параметров. В качестве архитектуры модели было решено выбрать ECAPA TDNN(из статьи ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in TDNN Based Speaker Verification). Res2Net — позволяет расширить рецептивное поле, захватывая более сложные пространственные зависимость,при этом не сильно увеличивая число параметров. SE-блоки (Squeeze-and-Excitation) — адаптивно выделяют важные каналы признаков. AttentiveStatsPooling — слой для агрегации признаков, который использует внимание для выделения важных временных срезов, комбинируя статистики (среднее и стандартное отклонение) для улучшения представления временных данных. Общее число параметров модели составляет **1 329 000**(c конкретными параметрами модели можно ознакомиться в Jupyter Notebook).

## 6. Экспериментальная установка

### 6.1. Обучение  
Модель обучалась с использованием оптимизатора Adam с начальной скоростью обучения 0.001. Для настройки скорости обучения использовался CosineAnnealingLR с параметром T_max=25. Такой подход помогает плавно уменьшать скорость обучения на протяжении всех эпох, улучшая сходимость модели. Во время обучения использовалась функция negative log-likelihood loss (nll_loss) для вычисления ошибки, а также выполнялся шаг оптимизации после каждого батча.

### 6.2. Функции оценки  
Для оценки качества модели использовалась функция cross-entropy loss на этапе обучения. Для более точной оценки качества модели на тестовых данных была реализована функция best_eer, которая вычисляет Equal Error Rate (EER). Это метрика, которая определяет точку, при которой количество ложных срабатываний и пропусков минимально и одинаково.

### 6.3. Процесс обучения  
Обучение проводилось в течение 25 эпох. Для каждой эпохи вычислялись Loss для train выборки и score(EER) для test выборкри.

## 7. Результаты экспериментов

По окончании обучения (25 эпох) были получены следующие результаты:

- **Обучающая выборка:**  
  - Потеря (CE Loss): ≈ 0.3922309032026327
  
- **Тестовая выборка:**  
  - EER: ≈8%

Эти результаты показывают, что модель достигла приемлемых показателей как на обучающей, так и на тестовой выборке, что указывает на низкий уровень переобучения. Однако, несмотря на достижение таких результатов, точность модели, выраженная через EER, оставляет возможности для улучшения(например увеличения кол-ва параметров, более тонкого подбора гиперпараметров и добавления contrastive loss).

## 8. Обсуждение и перспективы

### 8.1. Анализ текущих результатов  
Модель показала **EER** 8%, что говорит нам о том, что с 8% вероятснотью, с одной стороны мы негативно сработаем на позитивного пользователя, с другой стороны с 8% вероятснотью мы позитивного сработаем на ложного пользователя(мошенника), что , в целом, приемлимо, если наша модель voice-biometrics используется, например, для идентификации по голосу пользователя умной колонки. С другой стороны - если в нашей задаче критична точность(например вход в дом по голосу) эта модель недостаточно надежна.


C графиками обучения можно ознакомиться ниже:


![Loss](https://github.com/Cowwwperwood/Voice-Biometrics/blob/main/loss.png)


![EER](https://github.com/Cowwwperwood/Voice-Biometrics/blob/main/EER.png)




### 8.2. Возможные пути улучшения  
- **Увеличение сложности модели:** Добавление дополнительных слоёв трансформера или сверточных блоков,при этом нужно более тщательно подходить к вопросам переобучения.
- **Тонкая настройка гиперпараметров:** Изменение скорости обучения, увеличение количества эпох, подбор оптимальных параметров аугментаций.
- **Использование предобученных моделей:** Применение transfer learning с предобученными аудио моделями может значительно повысить качество классификации.
- **Добавление contrastive loss:** Теоритически этот метод обучения может повысить качества модели на 1-2% EER. 

## 9. Заключение

В данном проекте была реализована система для голосовой биометрии, использующая архитектуру EcapaTDNN для классификации звуков. Модель эффективно извлекает признаки из аудиофичей и демонстрирует хорошие результаты на тренировочных данных. 
